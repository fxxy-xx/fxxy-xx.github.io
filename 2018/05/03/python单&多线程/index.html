<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  
  
  <meta name="description" content="力争下游。">
  
  <title>
    python爬虫-单&amp;多线程 |
    
    fxxy
  </title>
  <!-- Icon -->
  
    <link rel="shortcut icon" href="/logo.png">
    
  
<link rel="stylesheet" href="/css/style.css">

  
  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="fxxy" type="application/atom+xml">
</head>

<body>
  <main class="content">
    <section class="outer">
  <article id="post-python单&amp;多线程" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
      

<h1 class="article-title" itemprop="name">
  python爬虫-单&amp;多线程
</h1>



    </header>
    

    
    <div class="article-meta">
      <a href="/2018/05/03/python%E5%8D%95&%E5%A4%9A%E7%BA%BF%E7%A8%8B/" class="article-date">
  <time datetime="2018-05-02T16:00:00.000Z" itemprop="datePublished">2018-05-03</time>
</a>
      
    </div>
    

    
    
<div class="tocbot"></div>

    

    <div class="article-entry" itemprop="articleBody">
      
      
      
      <ul>
<li>以抓取<a target="_blank" rel="noopener" href="https://www.pexels.com/%E7%BD%91%E7%AB%99%E5%9B%BE%E7%89%87%E4%B8%BA%E4%BE%8B">https://www.pexels.com/网站图片为例</a></li>
<li>前置基础：了解HTML的DOM解析结构</li>
</ul>
<span id="more"></span>

<h2 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h2><h3 id="获取网页html"><a href="#获取网页html" class="headerlink" title="获取网页html"></a>获取网页html</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.pexels.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">page1=request.Request(url,headers=headers)</span><br><span class="line">page=request.urlopen(page1)</span><br><span class="line"></span><br><span class="line">html=page.read()</span><br><span class="line"><span class="built_in">print</span>(html)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;test.html&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(html)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>

<h3 id="获取图片img标签"><a href="#获取图片img标签" class="headerlink" title="获取图片img标签"></a>获取图片img标签</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.pexels.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">page1=request.Request(url,headers=headers)</span><br><span class="line">page=request.urlopen(page1)</span><br><span class="line">soup = BeautifulSoup(page,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">srcs = soup.find_all(<span class="string">&#x27;img&#x27;</span>,<span class="string">&#x27;photo-item__img&#x27;</span>) <span class="comment">#查找class为photo-item__img的img标签</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> src <span class="keyword">in</span> srcs:</span><br><span class="line">    <span class="built_in">print</span>(src)</span><br></pre></td></tr></table></figure>

<h3 id="截取img标签中的图片url链接"><a href="#截取img标签中的图片url链接" class="headerlink" title="截取img标签中的图片url链接"></a>截取img标签中的图片url链接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.pexels.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">page1=request.Request(url,headers=headers)</span><br><span class="line">page=request.urlopen(page1)</span><br><span class="line">soup = BeautifulSoup(page,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">srcs = soup.find_all(<span class="string">&#x27;img&#x27;</span>,<span class="string">&#x27;photo-item__img&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> src <span class="keyword">in</span> srcs:</span><br><span class="line">    links = src.get(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(links)</span><br></pre></td></tr></table></figure>

<p><img src="https://i.imgur.com/BnNW3ht.png#alt=" alt="img"></p>
<h3 id="将去掉多余参数"><a href="#将去掉多余参数" class="headerlink" title="将去掉多余参数"></a>将去掉多余参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.pexels.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">page1=request.Request(url,headers=headers)</span><br><span class="line">page=request.urlopen(page1)</span><br><span class="line">soup = BeautifulSoup(page,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">srcs = soup.find_all(<span class="string">&#x27;img&#x27;</span>,<span class="string">&#x27;photo-item__img&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sr <span class="keyword">in</span> srcs:</span><br><span class="line">    links = sr.get(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    first_pos = links.index(<span class="string">&#x27;?&#x27;</span>)</span><br><span class="line">    last_pos = links.index(<span class="string">&#x27;500&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    split = links[first_pos : last_pos+<span class="number">3</span>]</span><br><span class="line">    links_final = links.replace(split,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(links_final)</span><br></pre></td></tr></table></figure>

<h3 id="写入本地"><a href="#写入本地" class="headerlink" title="写入本地"></a>写入本地</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.pexels.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">page1=request.Request(url,headers=headers)</span><br><span class="line">page=request.urlopen(page1)</span><br><span class="line">soup = BeautifulSoup(page,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">srcs = soup.find_all(<span class="string">&#x27;img&#x27;</span>,<span class="string">&#x27;photo-item__img&#x27;</span>)</span><br><span class="line"></span><br><span class="line">x=<span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> sr <span class="keyword">in</span> srcs:</span><br><span class="line">    url = sr.get(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    first_pos = links.index(<span class="string">&#x27;?&#x27;</span>)</span><br><span class="line">    last_pos = links.index(<span class="string">&#x27;5&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    split = links[first_pos : last_pos+<span class="number">3</span>]</span><br><span class="line">    url = links.replace(split,<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    path = <span class="string">r&#x27;D:\\img\\&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;https&#x27;</span> <span class="keyword">in</span> url:</span><br><span class="line">        url1 = request.Request(url,headers = headers)</span><br><span class="line">        url = request.urlopen(url1)</span><br><span class="line">        f = codecs.<span class="built_in">open</span>(path+<span class="string">&#x27;%s.jpg&#x27;</span>%(x), <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">        x+=<span class="number">1</span></span><br><span class="line">        f.write(url.read())</span><br><span class="line">        f.close()</span><br></pre></td></tr></table></figure>

<h3 id="最终版本"><a href="#最终版本" class="headerlink" title="最终版本"></a>最终版本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_url</span>(<span class="params">link</span>):</span><span class="comment">#在img标签中获取到图片的url，并去掉多余的参数</span></span><br><span class="line">    link = link.get(<span class="string">&#x27;src&#x27;</span>)<span class="comment">#获取img标签中的图片url</span></span><br><span class="line">    first_pos = link.index(<span class="string">&#x27;?&#x27;</span>)</span><br><span class="line">    last_pos = link.index(<span class="string">&#x27;5&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    split = link[first_pos : last_pos+<span class="number">3</span>]<span class="comment">#截取多余的参数</span></span><br><span class="line">    url = link.replace(split,<span class="string">&#x27;&#x27;</span>)<span class="comment">#用replace函数将多余的参数去掉</span></span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_img</span>(<span class="params">url,x</span>):</span><span class="comment">#保存图片</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;https&#x27;</span> <span class="keyword">in</span> url:</span><br><span class="line">        url = request.Request(url,headers = headers)</span><br><span class="line">        file = request.urlopen(url).read()</span><br><span class="line">        path = <span class="string">&#x27;./img&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">            path = path + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(path+<span class="string">&#x27;%s.jpg&#x27;</span>%x,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(file)</span><br><span class="line">                f.close()</span><br><span class="line">                flag = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            os.mkdir(path)</span><br><span class="line">            path = path + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(path+<span class="string">&#x27;%s.jpg&#x27;</span>%x,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(file)</span><br><span class="line">                f.close()</span><br><span class="line">                flag = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> flag:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> flag,url</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.pexels.com/&#x27;</span></span><br><span class="line"></span><br><span class="line">res = request.Request(url,headers = headers)</span><br><span class="line">res = request.urlopen(res)</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(res,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">links = soup.find_all(<span class="string">&#x27;img&#x27;</span>,<span class="string">&#x27;photo-item__img&#x27;</span>)</span><br><span class="line">x = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    url = cut_url(link)</span><br><span class="line">    flag = save_img(url,x)</span><br><span class="line">    x += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> flag:</span><br><span class="line">        <span class="built_in">print</span>(flag)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;bad&#x27;</span>+flag)</span><br></pre></td></tr></table></figure>

<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>多线程爬虫，分别用threadpool()和ThreadPoolExexutor()模块实现。</p>
<h3 id="threadpool模块"><a href="#threadpool模块" class="headerlink" title="threadpool模块"></a>threadpool模块</h3><p>核心代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pool = threadpool.ThreadPool(x)<span class="comment">#声明一个线程池，x表示需要线程数</span></span><br><span class="line">   requests = threadpool.makeRequests(function_name,参数)</span><br><span class="line">   <span class="keyword">for</span> req <span class="keyword">in</span> requests:</span><br><span class="line">       pool.putRequest(req)</span><br><span class="line">   pool.wait()<span class="comment">#等待所有子线程都执行完毕后再执行主线程下面的语句，否则会直接运行主线程</span></span><br></pre></td></tr></table></figure>

<p>这是声明一个线程池来将所有的线程再利用for循环一起启动，但是有一个坏处就是当线程多的时候就特别容易发生堵塞，适用于线程较少的时候</p>
<p>threadpool模块的爬虫代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> threadpool</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_run</span>(<span class="params">thread</span>):</span></span><br><span class="line">    thread.start()</span><br><span class="line"></span><br><span class="line">    thread.join()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_img</span>(<span class="params">url,name</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;tread %s is start &#x27;</span>%threading.current_thread().name)</span><br><span class="line"></span><br><span class="line">    flag = <span class="number">0</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    url = request.Request(url,headers = headers)</span><br><span class="line">    html = request.urlopen(url)</span><br><span class="line">    file = html.read()</span><br><span class="line">    path = <span class="string">&#x27;./wallroom2&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">        path = path + <span class="string">&#x27;/&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path+name,<span class="string">&#x27;ab+&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(file)</span><br><span class="line">            f.close()</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.mkdir(path)</span><br><span class="line">        path = path + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path+url,<span class="string">&#x27;ab+&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(file)</span><br><span class="line">            f.close()</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;the %s is ok&#x27;</span>%name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;the %s is fail&#x27;</span>%url)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_url</span>(<span class="params">url</span>):</span></span><br><span class="line">     headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">     res = request.Request(url,headers = headers)</span><br><span class="line">     html = request.urlopen(res).read()</span><br><span class="line"></span><br><span class="line">     soup = BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">     links = soup.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">     <span class="keyword">return</span> links</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_name</span>(<span class="params">url</span>):</span></span><br><span class="line"></span><br><span class="line">    pos = url.index(<span class="string">&#x27;bg-&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    name = url[pos:pos+<span class="number">10</span>] + <span class="string">&#x27;.jpeg&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(name)</span><br><span class="line">    <span class="keyword">return</span> name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    url = <span class="built_in">input</span>(<span class="string">&#x27;请输入wallroom的一个网址：&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    tread_list = []</span><br><span class="line"></span><br><span class="line">    links = get_url(url)</span><br><span class="line">    x = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">        url1 = link.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(url1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> url1.find(<span class="string">&#x27;bg&#x27;</span>) &gt; <span class="number">0</span>:</span><br><span class="line">            x += <span class="number">1</span></span><br><span class="line">            url_real = <span class="string">&#x27;https://wallroom.io&#x27;</span> + url1 +<span class="string">&#x27;/download&#x27;</span></span><br><span class="line">            <span class="built_in">print</span>(url_real)</span><br><span class="line"></span><br><span class="line">            name = set_name(url1)</span><br><span class="line">            thread_name = name</span><br><span class="line">            thread_name = threading.Thread(target=save_img,args = (url_real,name,))</span><br><span class="line">            names.append(name)</span><br><span class="line">            urls.append(url_real)</span><br><span class="line"></span><br><span class="line">            tread_list.append(thread_name)</span><br><span class="line">    <span class="comment">#for tread_list in range(10):</span></span><br><span class="line"></span><br><span class="line">    pool = threadpool.ThreadPool(x)</span><br><span class="line">    requests = threadpool.makeRequests(thread_run, tread_list)</span><br><span class="line">    <span class="keyword">for</span> req <span class="keyword">in</span> requests:</span><br><span class="line">        pool.putRequest(req)</span><br><span class="line">    pool.wait()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<h3 id="ThreadPoolExecutor模块"><a href="#ThreadPoolExecutor模块" class="headerlink" title="ThreadPoolExecutor模块"></a>ThreadPoolExecutor模块</h3><p><code>ThreadPoolExecutor</code>就提供了一个功能，可以规定在进程池里可以有多少线程在运行，在线程比较多的时候减少了资源的占用</p>
<p>核心代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">executor = ThreadPoolExecutor(x)<span class="comment">#线程池中能够进行的线程只能有x个</span></span><br><span class="line">    all_task = [executor.submit(save_img, (url)) <span class="keyword">for</span> url <span class="keyword">in</span> urls]</span><br><span class="line">    wait(all_task, return_when=ALL_COMPLETED)<span class="comment">#相当于threadpool中的wait()</span></span><br></pre></td></tr></table></figure>

<p>利用ThreadPoolExecutor爬虫的完整代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threadpool</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor , wait, ALL_COMPLETED, FIRST_COMPLETED</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_img</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;tread %s is start &#x27;</span>%threading.current_thread().name)</span><br><span class="line">    name = set_name(url)</span><br><span class="line">    flag = <span class="number">0</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    url = request.Request(url,headers = headers)</span><br><span class="line">    html = request.urlopen(url)</span><br><span class="line">    file = html.read()</span><br><span class="line">    path = <span class="string">&#x27;./wallroom2880&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">        path = path + <span class="string">&#x27;/&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path+name,<span class="string">&#x27;ab+&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(file)</span><br><span class="line">            f.close()</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.mkdir(path)</span><br><span class="line">        path = path + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path+url,<span class="string">&#x27;ab+&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(file)</span><br><span class="line">            f.close()</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> flag:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;the %s is ok&#x27;</span>%name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;the %s is fail&#x27;</span>%url)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_url</span>(<span class="params">url</span>):</span></span><br><span class="line">     headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">     res = request.Request(url,headers = headers)</span><br><span class="line">     html = request.urlopen(res).read()</span><br><span class="line"></span><br><span class="line">     soup = BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">     links = soup.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">     <span class="keyword">return</span> links</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_name</span>(<span class="params">url</span>):</span></span><br><span class="line"></span><br><span class="line">    pos = url.index(<span class="string">&#x27;bg-&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    name = url[pos:pos+<span class="number">10</span>] + <span class="string">&#x27;.jpeg&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> name</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    url = <span class="built_in">input</span>(<span class="string">&#x27;请输入wallroom的一个网址：&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    urls = []</span><br><span class="line"></span><br><span class="line">    links = get_url(url)</span><br><span class="line">    <span class="comment">#print(links)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">        url1 = link.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">        <span class="comment">#print(url1)</span></span><br><span class="line">        <span class="keyword">if</span> url1.find(<span class="string">&#x27;bg&#x27;</span>) &gt; <span class="number">0</span>:</span><br><span class="line">            url_real = <span class="string">&#x27;https://wallroom.io&#x27;</span> + url1 +<span class="string">&#x27;/download&#x27;</span></span><br><span class="line">            <span class="built_in">print</span>(url_real)</span><br><span class="line">            urls.append(url_real)</span><br><span class="line"></span><br><span class="line">    executor = ThreadPoolExecutor(<span class="number">10</span>)</span><br><span class="line">    all_task = [executor.submit(save_img, (url)) <span class="keyword">for</span> url <span class="keyword">in</span> urls]</span><br><span class="line">    wait(all_task, return_when=ALL_COMPLETED)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2018/05/03/python%E5%8D%95&%E5%A4%9A%E7%BA%BF%E7%A8%8B/" data-id="ckykyadbh000h9lu1a4pw3lp0" class="article-share-link">
        分享
      </a>
      
<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>

  </div>

  
  
<nav class="article-nav">
  
  <a href="/2018/06/30/student-%20manage/" class="article-nav-link">
    <strong class="article-nav-caption">前一篇</strong>
    <div class="article-nav-title">
      
      学生信息管理系统 - python
      
    </div>
  </a>
  
  
</nav>

  

  
  
  
<div class="gitalk" id="gitalk-container"></div>

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">


<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>


<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>

<script type="text/javascript">
  var gitalk = new Gitalk({
    clientID: 'f8f74efdbed061c45ee0',
    clientSecret: 'd8d152af5c2f877d584e9b17a559a72aed2279b7',
    repo: 'gitalk',
    owner: 'fxxy-xx',
    admin: ['fxxy-xx'],
    // id: location.pathname,      // Ensure uniqueness and length less than 50
    id: md5(location.pathname),
    distractionFreeMode: false,  // Facebook-like distraction free mode
    pagerDirection: 'last'
  })

  gitalk.render('gitalk-container')
</script>

  

</article>
</section>
    <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
  <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
  <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>fxxy &copy; 2022</li>
      
        <li></li>
      
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>theme  <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>
  </main>
  <aside class="sidebar">
    <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/logo.png" alt="fxxy"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">tags</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/links">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        搜索
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="fe fe-feed"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
  </aside>
  
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>



<script src="/fancybox/jquery.fancybox.min.js"></script>





<script src="/js/tocbot.min.js"></script>


<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
  });
</script>



<script src="/js/ocean.js"></script>

</body>

</html>